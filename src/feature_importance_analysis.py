"""
ç‰¹å¾´é‡é‡è¦åº¦åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ã‚¹ã‚³ã‚¢ã«æœ€ã‚‚å½±éŸ¿ã‚’ä¸ãˆã¦ã„ã‚‹è¦å› ã‚’ç‰¹å®šã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®åŸºç›¤ã¨ã™ã‚‹
"""

import pandas as pd
import numpy as np
import xgboost as xgb
import plotly.graph_objects as go
import plotly.express as px
from typing import List, Dict, Any
import os
from config import OUTPUT_DIR, OUTPUT_FILES


def get_feature_importance(
    model: xgb.XGBRegressor, feature_names: List[str]
) -> pd.DataFrame:
    """å­¦ç¿’æ¸ˆã¿XGBoostãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—"""
    print("ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—ä¸­...")

    importance_df = pd.DataFrame(
        {"feature": feature_names, "importance": model.feature_importances_}
    ).sort_values("importance", ascending=False)

    print(f"ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—å®Œäº†: {len(importance_df)}å€‹ã®ç‰¹å¾´é‡")
    return importance_df


def create_importance_bar_chart(importance_df: pd.DataFrame, top_n: int = 10) -> None:
    """ç‰¹å¾´é‡é‡è¦åº¦ã‚’æ£’ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–"""
    print(f"ç‰¹å¾´é‡é‡è¦åº¦ã®æ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆä¸­ï¼ˆä¸Šä½{top_n}å€‹ï¼‰...")

    top_features = importance_df.head(top_n)

    fig = go.Figure(
        data=[
            go.Bar(
                x=top_features["importance"],
                y=top_features["feature"],
                orientation="h",
                marker=dict(
                    color=px.colors.qualitative.Set3[: len(top_features)],
                    line=dict(color="black", width=1),
                ),
                text=[f"{imp:.3f}" for imp in top_features["importance"]],
                textposition="auto",
            )
        ]
    )

    fig.update_layout(
        title=f"ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½{top_n}å€‹ï¼‰",
        xaxis_title="é‡è¦åº¦",
        yaxis_title="ç‰¹å¾´é‡",
        width=800,
        height=max(400, len(top_features) * 40),
        yaxis=dict(autorange="reversed"),
    )

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    output_file = OUTPUT_DIR / OUTPUT_FILES["importance_chart"]
    fig.write_html(output_file)
    print(f"ç‰¹å¾´é‡é‡è¦åº¦ãƒãƒ£ãƒ¼ãƒˆã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")


def analyze_feature_impact(importance_df: pd.DataFrame) -> Dict[str, Any]:
    """ç‰¹å¾´é‡ã®å½±éŸ¿ã‚’åˆ†æ"""
    print("ç‰¹å¾´é‡ã®å½±éŸ¿ã‚’åˆ†æä¸­...")

    analysis = {
        "most_important_feature": {
            "name": importance_df.iloc[0]["feature"],
            "importance": importance_df.iloc[0]["importance"],
        },
        "top_3_features": [
            {"name": row["feature"], "importance": row["importance"]}
            for _, row in importance_df.head(3).iterrows()
        ],
        "miss_features": [
            {"name": row["feature"], "importance": row["importance"]}
            for _, row in importance_df[
                importance_df["feature"].str.contains("miss", case=False)
            ].iterrows()
        ],
        "score_features": [
            {"name": row["feature"], "importance": row["importance"]}
            for _, row in importance_df[
                importance_df["feature"].str.contains("score", case=False)
            ].iterrows()
        ],
        "importance_stats": {
            "mean": importance_df["importance"].mean(),
            "std": importance_df["importance"].std(),
            "max": importance_df["importance"].max(),
            "min": importance_df["importance"].min(),
        },
    }

    return analysis


def generate_insights_and_recommendations(analysis: Dict[str, Any]) -> None:
    """
    åˆ†æçµæœã‹ã‚‰æ´å¯Ÿã¨æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆã™ã‚‹

    Args:
        analysis: ç‰¹å¾´é‡åˆ†æçµæœ
    """
    print("\n=== ç‰¹å¾´é‡é‡è¦åº¦åˆ†æçµæœ ===")

    # æœ€ã‚‚é‡è¦ãªç‰¹å¾´é‡
    top_feature = analysis["most_important_feature"]
    print(
        f"æœ€ã‚‚é‡è¦ãªç‰¹å¾´é‡: {top_feature['name']} (é‡è¦åº¦: {top_feature['importance']:.3f})"
    )

    # ä¸Šä½3ã¤ã®ç‰¹å¾´é‡
    print("\nä¸Šä½3ã¤ã®ç‰¹å¾´é‡:")
    for i, feature in enumerate(analysis["top_3_features"], 1):
        print(f"{i}. {feature['name']}: {feature['importance']:.3f}")

    # ãƒŸã‚¹ã‚¿ã‚¤ãƒ—é–¢é€£ã®ç‰¹å¾´é‡
    if analysis["miss_features"]:
        print("\nãƒŸã‚¹ã‚¿ã‚¤ãƒ—é–¢é€£ã®ç‰¹å¾´é‡:")
        for feature in analysis["miss_features"]:
            print(f"- {feature['name']}: {feature['importance']:.3f}")
    else:
        print("\nãƒŸã‚¹ã‚¿ã‚¤ãƒ—é–¢é€£ã®ç‰¹å¾´é‡ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    # ã‚¹ã‚³ã‚¢é–¢é€£ã®ç‰¹å¾´é‡
    if analysis["score_features"]:
        print("\nã‚¹ã‚³ã‚¢é–¢é€£ã®ç‰¹å¾´é‡:")
        for feature in analysis["score_features"]:
            print(f"- {feature['name']}: {feature['importance']:.3f}")
    else:
        print("\nã‚¹ã‚³ã‚¢é–¢é€£ã®ç‰¹å¾´é‡ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    # æ´å¯Ÿã¨æ¨å¥¨äº‹é …
    print("\n=== æ´å¯Ÿã¨æ¨å¥¨äº‹é … ===")

    # ãƒŸã‚¹ã‚¿ã‚¤ãƒ—ã®å½±éŸ¿ã«ã¤ã„ã¦
    miss_features = analysis["miss_features"]
    if miss_features:
        avg_miss_importance = np.mean([f["importance"] for f in miss_features])
        print(f"ãƒŸã‚¹ã‚¿ã‚¤ãƒ—é–¢é€£ã®ç‰¹å¾´é‡ã®å¹³å‡é‡è¦åº¦: {avg_miss_importance:.3f}")

        if avg_miss_importance > analysis["importance_stats"]["mean"]:
            print("âœ… ãƒŸã‚¹ã‚¿ã‚¤ãƒ—ã¯ã‚¹ã‚³ã‚¢ã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã¦ã„ã¾ã™")
            print("ğŸ’¡ æ¨å¥¨: ãƒŸã‚¹ã‚¿ã‚¤ãƒ—ã‚’æ¸›ã‚‰ã™ã“ã¨ã§ã‚¹ã‚³ã‚¢å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™")
        else:
            print("âš ï¸ ãƒŸã‚¹ã‚¿ã‚¤ãƒ—ã®å½±éŸ¿ã¯ä¸­ç¨‹åº¦ã§ã™")
    else:
        print("âŒ ãƒŸã‚¹ã‚¿ã‚¤ãƒ—é–¢é€£ã®ç‰¹å¾´é‡ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€å½±éŸ¿ã‚’è©•ä¾¡ã§ãã¾ã›ã‚“")

    # éå»ã®ã‚¹ã‚³ã‚¢ã®å½±éŸ¿ã«ã¤ã„ã¦
    score_features = analysis["score_features"]
    if score_features:
        avg_score_importance = np.mean([f["importance"] for f in score_features])
        print(f"ã‚¹ã‚³ã‚¢é–¢é€£ã®ç‰¹å¾´é‡ã®å¹³å‡é‡è¦åº¦: {avg_score_importance:.3f}")

        if avg_score_importance > analysis["importance_stats"]["mean"]:
            print("âœ… éå»ã®ã‚¹ã‚³ã‚¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯é‡è¦ãªäºˆæ¸¬å› å­ã§ã™")
            print("ğŸ’¡ æ¨å¥¨: ä¸€è²«ã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ç¶­æŒãŒé‡è¦ã§ã™")

    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æ ¹æ‹ 
    print("\n=== ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æ ¹æ‹  ===")
    if miss_features:
        print("ãƒŸã‚¹ã‚¿ã‚¤ãƒ—ã‚’æ¸›ã‚‰ã›ã°ã‚¹ã‚³ã‚¢ãŒä¼¸ã³ã‚‹æ ¹æ‹ :")
        for feature in miss_features:
            print(f"- {feature['name']}ã®é‡è¦åº¦: {feature['importance']:.3f}")
            if "avg_miss" in feature["name"].lower():
                print("  â†’ éå»ã®ãƒŸã‚¹ã‚¿ã‚¤ãƒ—å¹³å‡ãŒé«˜ã„ã»ã©ã€ã‚¹ã‚³ã‚¢ãŒä¸‹ãŒã‚‹å‚¾å‘")
            elif "total_miss" in feature["name"].lower():
                print("  â†’ ç¾åœ¨ã®ãƒŸã‚¹ã‚¿ã‚¤ãƒ—æ•°ãŒé«˜ã„ã»ã©ã€ã‚¹ã‚³ã‚¢ãŒä¸‹ãŒã‚‹å‚¾å‘")
    else:
        print(
            "ãƒŸã‚¹ã‚¿ã‚¤ãƒ—é–¢é€£ã®ç‰¹å¾´é‡ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æ ¹æ‹ ã‚’æä¾›ã§ãã¾ã›ã‚“"
        )


def save_analysis_results(
    importance_df: pd.DataFrame, analysis: Dict[str, Any]
) -> None:
    """
    åˆ†æçµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹

    Args:
        importance_df: ç‰¹å¾´é‡é‡è¦åº¦ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        analysis: åˆ†æçµæœ
    """
    print("åˆ†æçµæœã‚’ä¿å­˜ä¸­...")

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # ç‰¹å¾´é‡é‡è¦åº¦ã‚’CSVã§ä¿å­˜
    csv_file = OUTPUT_DIR / OUTPUT_FILES["importance_csv"]
    importance_df.to_csv(csv_file, index=False, encoding="utf-8-sig")

    # åˆ†æçµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ä¿å­˜
    summary_file = OUTPUT_DIR / OUTPUT_FILES["analysis_summary"]
    with open(summary_file, "w", encoding="utf-8") as f:
        f.write("=== ç‰¹å¾´é‡é‡è¦åº¦åˆ†æã‚µãƒãƒªãƒ¼ ===\n\n")

        f.write("æœ€ã‚‚é‡è¦ãªç‰¹å¾´é‡:\n")
        top_feature = analysis["most_important_feature"]
        f.write(f"- {top_feature['name']}: {top_feature['importance']:.3f}\n\n")

        f.write("ä¸Šä½3ã¤ã®ç‰¹å¾´é‡:\n")
        for i, feature in enumerate(analysis["top_3_features"], 1):
            f.write(f"{i}. {feature['name']}: {feature['importance']:.3f}\n")

        f.write("\nãƒŸã‚¹ã‚¿ã‚¤ãƒ—é–¢é€£ã®ç‰¹å¾´é‡:\n")
        if analysis["miss_features"]:
            for feature in analysis["miss_features"]:
                f.write(f"- {feature['name']}: {feature['importance']:.3f}\n")
        else:
            f.write("- è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n")

        f.write("\nã‚¹ã‚³ã‚¢é–¢é€£ã®ç‰¹å¾´é‡:\n")
        if analysis["score_features"]:
            for feature in analysis["score_features"]:
                f.write(f"- {feature['name']}: {feature['importance']:.3f}\n")
        else:
            f.write("- è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n")

    print("åˆ†æçµæœã‚’ output/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã—ã¾ã—ãŸ")


def analyze_feature_importance(
    model: xgb.XGBRegressor, feature_names: List[str]
) -> None:
    """
    ç‰¹å¾´é‡é‡è¦åº¦åˆ†æã®ãƒ¡ã‚¤ãƒ³é–¢æ•°

    Args:
        model: å­¦ç¿’æ¸ˆã¿XGBoostãƒ¢ãƒ‡ãƒ«
        feature_names: ç‰¹å¾´é‡åã®ãƒªã‚¹ãƒˆ
    """
    # 1. ç‰¹å¾´é‡é‡è¦åº¦ã®å–å¾—
    importance_df = get_feature_importance(model, feature_names)

    # 2. é‡è¦åº¦ã®å¯è¦–åŒ–
    create_importance_bar_chart(importance_df, top_n=10)

    # 3. ç‰¹å¾´é‡ã®å½±éŸ¿åˆ†æ
    analysis = analyze_feature_impact(importance_df)

    # 4. æ´å¯Ÿã¨æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
    generate_insights_and_recommendations(analysis)

    # 5. çµæœã®ä¿å­˜
    save_analysis_results(importance_df, analysis)

    print("\nç‰¹å¾´é‡é‡è¦åº¦åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    import numpy as np

    np.random.seed(42)

    # ãƒ€ãƒŸãƒ¼ã®ç‰¹å¾´é‡å
    feature_names = [
        "user_id",
        "score",
        "total_miss",
        "prev_score",
        "avg_score_3",
        "avg_miss_3",
        "score_std_3",
        "max_score_3",
        "min_score_3",
    ]

    # ãƒ€ãƒŸãƒ¼ã®é‡è¦åº¦ï¼ˆåˆè¨ˆãŒ1ã«ãªã‚‹ã‚ˆã†ã«æ­£è¦åŒ–ï¼‰
    importance_scores = np.random.random(len(feature_names))
    importance_scores = importance_scores / importance_scores.sum()

    # ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
    class DummyModel:
        def __init__(self, feature_importances):
            self.feature_importances_ = feature_importances

    dummy_model = DummyModel(importance_scores)

    # ç‰¹å¾´é‡é‡è¦åº¦åˆ†æã®ãƒ†ã‚¹ãƒˆ
    analyze_feature_importance(dummy_model, feature_names)
